{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN—test0719.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP54lPLeP6AKakcshxydeJN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"q-vA7W31HLTo","colab_type":"text"},"source":["## 图像数据读取和处理"]},{"cell_type":"markdown","metadata":{"id":"HjH32Cp8SON7","colab_type":"text"},"source":["### 从Github下载图片数据"]},{"cell_type":"code","metadata":{"id":"d-hxiTc7SlPt","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QF2G70iuHF1N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"ok","timestamp":1595132122872,"user_tz":-480,"elapsed":8395,"user":{"displayName":"周尉阳","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTKLMpcfIq9vdPt1QQyeIS64dyhcfjcYMqI2RN=s64","userId":"12403260934929188499"}},"outputId":"e397e6af-77de-46c6-d641-f8e45c041743"},"source":["!git clone https://github.com/Zwysun/CNN.git\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'CNN'...\n","remote: Enumerating objects: 643, done.\u001b[K\n","remote: Counting objects:   0% (1/643)\u001b[K\rremote: Counting objects:   1% (7/643)\u001b[K\rremote: Counting objects:   2% (13/643)\u001b[K\rremote: Counting objects:   3% (20/643)\u001b[K\rremote: Counting objects:   4% (26/643)\u001b[K\rremote: Counting objects:   5% (33/643)\u001b[K\rremote: Counting objects:   6% (39/643)\u001b[K\rremote: Counting objects:   7% (46/643)\u001b[K\rremote: Counting objects:   8% (52/643)\u001b[K\rremote: Counting objects:   9% (58/643)\u001b[K\rremote: Counting objects:  10% (65/643)\u001b[K\rremote: Counting objects:  11% (71/643)\u001b[K\rremote: Counting objects:  12% (78/643)\u001b[K\rremote: Counting objects:  13% (84/643)\u001b[K\rremote: Counting objects:  14% (91/643)\u001b[K\rremote: Counting objects:  15% (97/643)\u001b[K\rremote: Counting objects:  16% (103/643)\u001b[K\rremote: Counting objects:  17% (110/643)\u001b[K\rremote: Counting objects:  18% (116/643)\u001b[K\rremote: Counting objects:  19% (123/643)\u001b[K\rremote: Counting objects:  20% (129/643)\u001b[K\rremote: Counting objects:  21% (136/643)\u001b[K\rremote: Counting objects:  22% (142/643)\u001b[K\rremote: Counting objects:  23% (148/643)\u001b[K\rremote: Counting objects:  24% (155/643)\u001b[K\rremote: Counting objects:  25% (161/643)\u001b[K\rremote: Counting objects:  26% (168/643)\u001b[K\rremote: Counting objects:  27% (174/643)\u001b[K\rremote: Counting objects:  28% (181/643)\u001b[K\rremote: Counting objects:  29% (187/643)\u001b[K\rremote: Counting objects:  30% (193/643)\u001b[K\rremote: Counting objects:  31% (200/643)\u001b[K\rremote: Counting objects:  32% (206/643)\u001b[K\rremote: Counting objects:  33% (213/643)\u001b[K\rremote: Counting objects:  34% (219/643)\u001b[K\rremote: Counting objects:  35% (226/643)\u001b[K\rremote: Counting objects:  36% (232/643)\u001b[K\rremote: Counting objects:  37% (238/643)\u001b[K\rremote: Counting objects:  38% (245/643)\u001b[K\rremote: Counting objects:  39% (251/643)\u001b[K\rremote: Counting objects:  40% (258/643)\u001b[K\rremote: Counting objects:  41% (264/643)\u001b[K\rremote: Counting objects:  42% (271/643)\u001b[K\rremote: Counting objects:  43% (277/643)\u001b[K\rremote: Counting objects:  44% (283/643)\u001b[K\rremote: Counting objects:  45% (290/643)\u001b[K\rremote: Counting objects:  46% (296/643)\u001b[K\rremote: Counting objects:  47% (303/643)\u001b[K\rremote: Counting objects:  48% (309/643)\u001b[K\rremote: Counting objects:  49% (316/643)\u001b[K\rremote: Counting objects:  50% (322/643)\u001b[K\rremote: Counting objects:  51% (328/643)\u001b[K\rremote: Counting objects:  52% (335/643)\u001b[K\rremote: Counting objects:  53% (341/643)\u001b[K\rremote: Counting objects:  54% (348/643)\u001b[K\rremote: Counting objects:  55% (354/643)\u001b[K\rremote: Counting objects:  56% (361/643)\u001b[K\rremote: Counting objects:  57% (367/643)\u001b[K\rremote: Counting objects:  58% (373/643)\u001b[K\rremote: Counting objects:  59% (380/643)\u001b[K\rremote: Counting objects:  60% (386/643)\u001b[K\rremote: Counting objects:  61% (393/643)\u001b[K\rremote: Counting objects:  62% (399/643)\u001b[K\rremote: Counting objects:  63% (406/643)\u001b[K\rremote: Counting objects:  64% (412/643)\u001b[K\rremote: Counting objects:  65% (418/643)\u001b[K\rremote: Counting objects:  66% (425/643)\u001b[K\rremote: Counting objects:  67% (431/643)\u001b[K\rremote: Counting objects:  68% (438/643)\u001b[K\rremote: Counting objects:  69% (444/643)\u001b[K\rremote: Counting objects:  70% (451/643)\u001b[K\rremote: Counting objects:  71% (457/643)\u001b[K\rremote: Counting objects:  72% (463/643)\u001b[K\rremote: Counting objects:  73% (470/643)\u001b[K\rremote: Counting objects:  74% (476/643)\u001b[K\rremote: Counting objects:  75% (483/643)\u001b[K\rremote: Counting objects:  76% (489/643)\u001b[K\rremote: Counting objects:  77% (496/643)\u001b[K\rremote: Counting objects:  78% (502/643)\u001b[K\rremote: Counting objects:  79% (508/643)\u001b[K\rremote: Counting objects:  80% (515/643)\u001b[K\rremote: Counting objects:  81% (521/643)\u001b[K\rremote: Counting objects:  82% (528/643)\u001b[K\rremote: Counting objects:  83% (534/643)\u001b[K\rremote: Counting objects:  84% (541/643)\u001b[K\rremote: Counting objects:  85% (547/643)\u001b[K\rremote: Counting objects:  86% (553/643)\u001b[K\rremote: Counting objects:  87% (560/643)\u001b[K\rremote: Counting objects:  88% (566/643)\u001b[K\rremote: Counting objects:  89% (573/643)\u001b[K\rremote: Counting objects:  90% (579/643)\u001b[K\rremote: Counting objects:  91% (586/643)\u001b[K\rremote: Counting objects:  92% (592/643)\u001b[K\rremote: Counting objects:  93% (598/643)\u001b[K\rremote: Counting objects:  94% (605/643)\u001b[K\rremote: Counting objects:  95% (611/643)\u001b[K\rremote: Counting objects:  96% (618/643)\u001b[K\rremote: Counting objects:  97% (624/643)\u001b[K\rremote: Counting objects:  98% (631/643)\u001b[K\rremote: Counting objects:  99% (637/643)\u001b[K\rremote: Counting objects: 100% (643/643)\u001b[K\rremote: Counting objects: 100% (643/643), done.\u001b[K\n","remote: Compressing objects: 100% (503/503), done.\u001b[K\n","remote: Total 643 (delta 138), reused 640 (delta 138), pack-reused 0\u001b[K\n","Receiving objects: 100% (643/643), 31.28 MiB | 30.48 MiB/s, done.\n","Resolving deltas: 100% (138/138), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c1hajzb2SKoa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595132135556,"user_tz":-480,"elapsed":3945,"user":{"displayName":"周尉阳","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTKLMpcfIq9vdPt1QQyeIS64dyhcfjcYMqI2RN=s64","userId":"12403260934929188499"}},"outputId":"0732fc88-ae20-4f7b-94e8-733a7803feda"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CNN  sample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nRpYQGJ3SWB-","colab_type":"text"},"source":["### 读取数据"]},{"cell_type":"markdown","metadata":{"id":"dE3uGt_FHT8N","colab_type":"text"},"source":["## 加载预训练模型（DenseNet）"]},{"cell_type":"code","metadata":{"id":"68oSnRs7HaHf","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from torch import nn\n","import torchvision.models as models\n","\n","densenet = models.densenet161(pretrained=True)\n","\n","densenet.classifier = nn.Linear(in_features=2208, out_features=19, bias=True)  # 输出层参数修改\n","densenet.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # 输入参数修改\n","print(densenet)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WUW9WiqRK9_J","colab_type":"code","colab":{}},"source":["def trainandsave(): \n","    trainloader = loadtraindata() # 神经网络结构\n","    net = Net()\n","    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 学习率为0.001 criterion = nn.CrossEntropyLoss() # 损失函数也可以自己定义，我们这里用的交叉熵损失函数 # 训练部分\n","    \n","    for epoch in range(5): # 训练的数据量为5个epoch，每个epoch为一个循环\n","                            # 每个epoch要训练所有的图片，每训练完成200张便打印一下训练的效果（loss值）\n","        running_loss = 0.0  # 定义一个变量方便我们对loss进行输出\n","        for i, data in enumerate(trainloader, 0): # 这里我们遇到了第一步中出现的trailoader，代码传入数据\n","            # enumerate是python的内置函数，既获得索引也获得数据\n","            # get the inputs\n","            inputs, labels = data # data是从enumerate返回的data，包含数据和标签信息，分别赋值给inputs和labels\n","\n","            # wrap them in Variable\n","            inputs, labels = Variable(inputs), Variable(labels) # 转换数据格式用Variable\n","           \n","            optimizer.zero_grad() # 梯度置零，因为反向传播过程中梯度会累加上一次循环的梯度\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs) # 把数据输进CNN网络net\n","            loss = criterion(outputs, labels) # 计算损失值\n","            loss.backward() # loss反向传播\n","            optimizer.step() # 反向传播后参数更新 \n","            running_loss += loss.data[0]      # loss累加\n","            if i % 200 == 199:\n","                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200)) # 然后再除以200，就得到这两百次的平均损失值\n","                running_loss = 0.0  # 这一个200次结束后，就把running_loss归零，下一个200次继续使用\n","\n","    print('Finished Training') # 保存神经网络\n","    torch.save(net, 'net.pkl') # 保存整个神经网络的结构和模型参数\n","    torch.save(net.state_dict(), 'net_params.pkl') # 只保存神经网络的模型参数"],"execution_count":null,"outputs":[]}]}